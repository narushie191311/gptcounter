#!/usr/bin/env python3
"""
ç©¶æ¥µæ€§èƒ½ä¸¦åˆ—å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ETAåˆ¶å¾¡ä»˜ãã®æœ€é«˜å“è³ªå‡¦ç† + ä¸­æ–­å†é–‹å¯¾å¿œ
"""

import os
import sys
import subprocess
import multiprocessing as mp
import json
import time
import signal
from pathlib import Path
import argparse
import psutil
import pickle

class UltimateParallelProcessor:
    def __init__(self, video_path, num_chunks, config_name, eta_target=None, output_csv=None):
        self.video_path = video_path
        self.num_chunks = num_chunks
        self.config_name = config_name
        self.eta_target = eta_target
        self.output_csv = output_csv or "outputs/ultimate_merged_analysis.csv"
        self.start_time = None
        self.chunk_results = []
        self.resume_file = "outputs/parallel_resume_state.json"
        
        # è¨­å®šèª­ã¿è¾¼ã¿
        with open("colab_ultimate_config.json", "r") as f:
            self.configs = json.load(f)
        
        self.config = self.configs[config_name]
        
        # ä¸­æ–­ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¸­æ–­ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        print(f"\nâš ï¸ ä¸­æ–­ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        self._save_resume_state()
        print("ä¸­æ–­çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚åŒã˜ã‚³ãƒãƒ³ãƒ‰ã§å†é–‹ã§ãã¾ã™ã€‚")
        sys.exit(0)
    
    def _save_resume_state(self):
        """å†é–‹çŠ¶æ…‹ã‚’ä¿å­˜"""
        resume_state = {
            "video_path": self.video_path,
            "num_chunks": self.num_chunks,
            "config_name": self.config_name,
            "eta_target": self.eta_target,
            "output_csv": self.output_csv,
            "chunk_results": self.chunk_results,
            "start_time": self.start_time,
            "timestamp": time.time()
        }
        
        Path("outputs").mkdir(exist_ok=True)
        with open(self.resume_file, "w") as f:
            json.dump(resume_state, f, indent=2)
    
    def _load_resume_state(self):
        """å†é–‹çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.resume_file):
            try:
                with open(self.resume_file, "r") as f:
                    resume_state = json.load(f)
                
                print(f"ğŸ”„ å†é–‹çŠ¶æ…‹ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼ˆ{time.ctime(resume_state['timestamp'])}ï¼‰")
                
                # å†é–‹ç¢ºèª
                response = input("ä¸­æ–­ã•ã‚ŒãŸå‡¦ç†ã‚’å†é–‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
                if response.lower() == 'y':
                    self.chunk_results = resume_state.get("chunk_results", [])
                    self.start_time = resume_state.get("start_time")
                    print(f"âœ“ {len(self.chunk_results)} ãƒãƒ£ãƒ³ã‚¯ã®çŠ¶æ…‹ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
                    return True
                else:
                    print("æ–°è¦å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™")
                    return False
            except:
                print("å†é–‹çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ–°è¦å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        
        return False
    
    def process_chunk(self, args):
        """ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆpickleå¯èƒ½ãªé–¢æ•°ï¼‰"""
        chunk_id, start_sec, duration_sec = args
        
        output_csv = f"outputs/chunks/chunk_{chunk_id:03d}.csv"
        output_video = f"outputs/chunks/chunk_{chunk_id:03d}.mp4"
        
        cmd = self._build_chunk_command(chunk_id, start_sec, duration_sec, output_csv, output_video)
        
        print(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_id}: {start_sec}s - {start_sec + duration_sec}s é–‹å§‹")
        
        try:
            # å‡¦ç†é–‹å§‹
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ“ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} å®Œäº†")
                return True, chunk_id, output_csv
            else:
                print(f"âœ— ãƒãƒ£ãƒ³ã‚¯ {chunk_id} å¤±æ•—: {result.stderr}")
                return False, chunk_id, None
                
        except Exception as e:
            print(f"âœ— ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚¨ãƒ©ãƒ¼: {e}")
            return False, chunk_id, None
    
    def _build_chunk_command(self, chunk_id, start_sec, duration_sec, output_csv, output_video):
        """ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰"""
        cmd = f'''python scripts/analyze_video_mac.py \\
          --video "{self.video_path}" \\
          --start-sec {start_sec} \\
          --duration-sec {duration_sec} \\
          --output-csv {output_csv} \\
          --device cuda \\
          --yolo-weights {self.config['yolo_weights']} \\
          --reid-backend {self.config['reid_backend']} \\
          --face-model {self.config['face_model']} \\
          --det-size {self.config['det_size']} \\
          --detect-every-n {self.config['detect_every_n']} \\
          --log-every-sec {self.config['log_every_sec']} \\
          --checkpoint-every-sec {self.config['checkpoint_every_sec']} \\
          --merge-every-sec {self.config['merge_every_sec']} \\
          --flush-every-n {self.config['flush_every_n']} \\
          --save-video --video-out {output_video} \\
          --no-show'''
        
        if self.config.get('gait_features'):
            cmd += " --gait-features"
        
        return cmd
    
    def execute_with_eta_control(self):
        """ETAåˆ¶å¾¡ä»˜ãã§å®Ÿè¡Œ"""
        # å†é–‹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
        resumed = self._load_resume_state()
        
        if not resumed:
            self.start_time = time.time()
        
        # å‹•ç”»æƒ…å ±å–å¾—
        video_info = self._get_video_info()
        if not video_info:
            return False
        
        print(f"å‹•ç”»æƒ…å ±: {video_info['total_frames']} ãƒ•ãƒ¬ãƒ¼ãƒ , {video_info['fps']:.2f} FPS, {video_info['total_duration']:.1f} ç§’")
        
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = self._create_chunks(video_info['total_duration'])
        
        # æ—¢ã«å®Œäº†ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’é™¤å¤–
        completed_chunk_ids = {result[1] for result in self.chunk_results}
        remaining_chunks = [chunk for chunk in chunks if chunk[0] not in completed_chunk_ids]
        
        if remaining_chunks:
            print(f"ğŸ”„ æ®‹ã‚Š {len(remaining_chunks)} ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¾ã™")
        else:
            print("ğŸ‰ å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ãŒå®Œäº†ã—ã¦ã„ã¾ã™")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Path("outputs/chunks").mkdir(parents=True, exist_ok=True)
        
        # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
        print(f"ç©¶æ¥µæ€§èƒ½ä¸¦åˆ—å‡¦ç†é–‹å§‹: {len(remaining_chunks)} ãƒãƒ£ãƒ³ã‚¯")
        
        if remaining_chunks:
            with mp.Pool(processes=min(len(remaining_chunks), mp.cpu_count())) as pool:
                results = pool.map(self.process_chunk, remaining_chunks)
                
                # çµæœã‚’æ—¢å­˜ã®çµæœã«è¿½åŠ 
                for result in results:
                    if result[0]:  # æˆåŠŸ
                        self.chunk_results.append(result)
                        # éšæ™‚çŠ¶æ…‹ä¿å­˜
                        self._save_resume_state()
        
        # çµæœé›†è¨ˆ
        successful_chunks = [result[2] for result in self.chunk_results if result[0]]
        
        end_time = time.time()
        processing_time = end_time - (self.start_time or end_time)
        
        print(f"\nğŸ‰ ä¸¦åˆ—å‡¦ç†å®Œäº†: {len(successful_chunks)}/{self.num_chunks} ãƒãƒ£ãƒ³ã‚¯æˆåŠŸ")
        print(f"å‡¦ç†æ™‚é–“: {processing_time:.1f} ç§’")
        print(f"é€Ÿåº¦: {video_info['total_duration']/processing_time:.2f}x ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ")
        
        # ETAåˆ¶å¾¡çµæœ
        if self.eta_target:
            if processing_time <= self.eta_target:
                print(f"âœ… ç›®æ¨™æ™‚é–“ {self.eta_target:.1f}ç§’ å†…ã§å®Œäº†ï¼")
            else:
                print(f"âš ï¸ ç›®æ¨™æ™‚é–“ {self.eta_target:.1f}ç§’ ã‚’ {processing_time - self.eta_target:.1f}ç§’ è¶…é")
        
        # ãƒãƒ£ãƒ³ã‚¯çµæœã‚’ãƒãƒ¼ã‚¸
        if successful_chunks:
            self._merge_chunks(successful_chunks, self.output_csv)
        
        # å®Œäº†å¾Œã¯å†é–‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(self.resume_file):
            os.remove(self.resume_file)
            print("âœ“ å†é–‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        
        return len(successful_chunks) == self.num_chunks
    
    def _get_video_info(self):
        """å‹•ç”»æƒ…å ±ã‚’å–å¾—"""
        try:
            import cv2
            cap = cv2.VideoCapture(self.video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_duration = total_frames / fps
            cap.release()
            return {"total_frames": total_frames, "fps": fps, "total_duration": total_duration}
        except:
            print("å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—")
            return None
    
    def _create_chunks(self, total_duration):
        """ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²"""
        chunk_duration = total_duration / self.num_chunks
        chunks = []
        
        for i in range(self.num_chunks):
            start_sec = i * chunk_duration
            duration_sec = chunk_duration
            if i == self.num_chunks - 1:
                duration_sec = total_duration - start_sec
            chunks.append((i, start_sec, duration_sec))
        
        return chunks
    
    def _merge_chunks(self, chunk_files, output_file):
        """ãƒãƒ£ãƒ³ã‚¯çµæœã‚’ãƒãƒ¼ã‚¸"""
        print("ãƒãƒ£ãƒ³ã‚¯çµæœã‚’ãƒãƒ¼ã‚¸ä¸­...")
        
        import pandas as pd
        
        dfs = []
        for chunk_file in chunk_files:
            if os.path.exists(chunk_file):
                df = pd.read_csv(chunk_file)
                dfs.append(df)
        
        if dfs:
            merged_df = pd.concat(dfs, ignore_index=True)
            merged_df.to_csv(output_file, index=False)
            print(f"âœ“ ãƒãƒ¼ã‚¸å®Œäº†: {output_file}")
            print(f"  ç·æ¤œå‡ºæ•°: {len(merged_df)}")
            print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯äººç‰©æ•°: {merged_df['person_id'].nunique() if 'person_id' in merged_df.columns else 'N/A'}")
        else:
            print("âœ— ãƒãƒ¼ã‚¸ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def main():
    parser = argparse.ArgumentParser(description="ç©¶æ¥µæ€§èƒ½ä¸¦åˆ—å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument("--video", required=True, help="å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--chunks", type=int, default=4, help="ãƒãƒ£ãƒ³ã‚¯æ•°")
    parser.add_argument("--config", default="ultimate", 
                       choices=["ultimate", "high_performance", "balanced", "fast"],
                       help="è¨­å®šãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--eta-target", type=float, help="ç›®æ¨™å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰")
    parser.add_argument("--output-csv", help="å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    
    args = parser.parse_args()
    
    processor = UltimateParallelProcessor(
        args.video, 
        args.chunks, 
        args.config, 
        args.eta_target,
        args.output_csv
    )
    success = processor.execute_with_eta_control()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
